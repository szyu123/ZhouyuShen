---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a final-year Ph.D. student in Econometrics and Statistics at the University of Chicago Booth School of Business, where I am advised by [Prof. Dacheng Xiu](https://dachxiu.chicagobooth.edu/). Prior to UChicago, I obtained a B.S. in Statistics from the School of the Gifted Young, University of Science and Technology of China in 2020. My research lies in the intersection of econometrics, statistics, and machine learning, with a focus on providing theoretical guarantees for applying machine learning methods in the field of economics and finance.

**Email**: zshen10@chicagobooth.edu

**[Download CV](_pages/CV.pdf)** 

## Research
**On the Theory of RNNs** (with Xiao Chen, Yu Chen, and Dacheng Xiu)  
<span style="color:gray;">Coming Soon</span>

_Recurrent Neural Networks (RNNs)_ are a class of neural networks designed for sequential data, including time series. This paper explores RNNs' mechanisms by providing theoretical guarantees within time series models. We analyze a nonlinear autoregressive and moving-average model (NARMA) and establish a statistical error bound for RNN predictions. The bound includes approximation and estimation errors, influenced by the RNN's architecture and process properties. Simulations demonstrate that RNNs outperform ARMA and deep neural networks (DNNs) in prediction accuracy.

---

**On the Theory of Deep Autoencoders** (with Dacheng Xiu)  
<span style="color:gray;">Coming Soon</span>

_Autoencoders_ are widely used for dimensionality reduction and signal denoising. This study provides non-asymptotic guarantees for deep autoencoders within a nonlinear factor model. We show that deep autoencoders recover common components from inputs with diminishing error as dimensionality and sample size increase. The recovered factors converge to the true latent factors through functional transformation. Applications include nowcasting GDP growth, asset return pricing, and program evaluation.

---

**[Can Machines Learn Weak Signals?](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4722678)** (with Dacheng Xiu)  
<span style="color:gray;">Working paper, winner of the 2024 Bates-White Prize for the Best Paper at SoFiE Annual Conference.</span>

We evaluate machine learning algorithms in high-dimensional regression with low signal-to-noise ratios. Ridge regression performs better than Lasso under weak signals. Simulations show Random Forest generally outperforms Gradient Boosted Trees, and Neural Networks with L_2-regularization excel in capturing nonlinear functions of weak signals. Empirical results suggest signal weakness limits Lasso's performance in economic predictions.

---

**[Modeling Tail Index With Autoregressive Conditional Pareto Model](https://www.tandfonline.com/doi/abs/10.1080/07350015.2020.1832504)** (with Yu Chen and Ruxin Shi)  
<span style="color:gray;">Journal of Business & Economic Statistics, Volume 40, 2022</span>

We propose an autoregressive conditional Pareto (AcP) model to dynamically model the tail index in financial markets using an exponential function for greater interpretability. The model is superior to GARCH for volatility estimation, especially during market turmoil. The estimated tail index reflects stock market risk and may serve as an early warning indicator. We also calculate tail connectedness, showing it increases during turbulent periods, aligning with score-based methods.

